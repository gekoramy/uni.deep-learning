{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDvbK8srqEwq"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "if ! [ -d dataset ]; then\n",
        "  mkdir dataset &&\n",
        "  gdown 1P8a1g76lDJ8cMIXjNDdboaRR5-HsVmUb &&\n",
        "  tar -xf refcocog.tar.gz -C dataset &&\n",
        "  rm refcocog.tar.gz\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h397tWQMo708"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "tee requirements.txt << END\n",
        "jaxtyping\n",
        "matplotlib\n",
        "pandas\n",
        "pydantic\n",
        "timm\n",
        "torch\n",
        "torchvision\n",
        "tqdm\n",
        "transformers\n",
        "ultralytics\n",
        "more-itertools\n",
        "END\n",
        "\n",
        "pip install -q -r requirements.txt\n",
        "pip install -q -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc7bB-vnpxnL"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import logging\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "import torch\n",
        "import torchvision\n",
        "import PIL\n",
        "import itertools as it\n",
        "import pandas as pd\n",
        "import more_itertools as mit\n",
        "\n",
        "from datetime import datetime\n",
        "from jaxtyping import Float, UInt, Int\n",
        "from pydantic.dataclasses import dataclass\n",
        "from torchvision.io import read_image\n",
        "from torchvision.ops import box_convert, box_iou\n",
        "from tqdm import tqdm\n",
        "from typing import Literal, Callable, Mapping, TypeVar, Iterator, Iterable\n",
        "from ultralytics import YOLO\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "from csv import writer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdj647iYqJsG"
      },
      "outputs": [],
      "source": [
        "root = os.path.join(\"dataset\", \"refcocog\", \"\")\n",
        "data_instances = os.path.join(root, \"annotations\", \"instances.json\")\n",
        "data_refs = os.path.join(root, \"annotations\", \"refs(umd).p\")\n",
        "data_images = os.path.join(root, \"images\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t03kUMG1qPUo"
      },
      "outputs": [],
      "source": [
        "Split = Literal[\"train\", \"test\", \"val\"]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Info:\n",
        "    description: str  # This is stable 1.0 version of the 2014 MS COCO dataset.\n",
        "    url: str  # http://mscoco.org/\n",
        "    version: str  # 1.0\n",
        "    year: int  # 2014\n",
        "    contributor: str  # Microsoft COCO group\n",
        "    date_created: datetime  # 2015-01-27 09:11:52.357475\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Image:\n",
        "    license: int  # each image has an associated licence id\n",
        "    file_name: str  # file name of the image\n",
        "    coco_url: str  # example http://mscoco.org/images/131074\n",
        "    height: int\n",
        "    width: int\n",
        "    flickr_url: str  # example http://farm9.staticflickr.com/8308/7908210548_33e\n",
        "    id: int  # id of the imag\n",
        "    date_captured: datetime  # example '2013-11-21 01:03:06'\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class License:\n",
        "    url: str  # example http://creativecommons.org/licenses/by-nc-sa/2.0/\n",
        "    id: int  # id of the licence\n",
        "    name: str  # example 'Attribution-NonCommercial-ShareAlike License\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Annotation:\n",
        "    # segmentation: list[list[float]]\n",
        "    area: float  # number of pixel of the described object\n",
        "    iscrowd: Literal[\n",
        "        1, 0\n",
        "    ]  # Crowd annotations (iscrowd=1) are used to label large groups of objects (e.g. a crowd of people)\n",
        "    image_id: int  # id of the target image\n",
        "    bbox: tuple[\n",
        "        float, float, float, float\n",
        "    ]  # bounding box coordinates [xmin, ymin, width, height]\n",
        "    category_id: int\n",
        "    id: int  # annotation id\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Category:\n",
        "    supercategory: str  # example 'vehicle'\n",
        "    id: int  # category id\n",
        "    name: str  # example 'airplane'\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Instances:\n",
        "    info: Info\n",
        "    images: list[Image]\n",
        "    licenses: list[License]\n",
        "    annotations: list[Annotation]\n",
        "    categories: list[Category]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhgDFVVJrzWj"
      },
      "outputs": [],
      "source": [
        "with open(data_instances, \"r\") as f:\n",
        "    raw = json.load(f)\n",
        "\n",
        "instances: Instances = Instances(**raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L3YC0obylAp"
      },
      "outputs": [],
      "source": [
        "device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSV_FVH-S3A9"
      },
      "outputs": [],
      "source": [
        "def store_bboxes(\n",
        "    name_model: str, bbox_model: Callable[[PIL.Image], Float[torch.Tensor, \"X 5\"]]\n",
        ") -> None:\n",
        "\n",
        "    with open(f\"bboxes[{name_model}].csv\", \"a\") as f:\n",
        "        wr = writer(f)\n",
        "        wr.writerow([\"file_name\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"confidence\"])\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            img: Image\n",
        "\n",
        "            for img in tqdm(instances.images):\n",
        "\n",
        "                pil: PIL.Image = PIL.Image.open(os.path.join(data_images, img.file_name)).convert(\"RGB\")\n",
        "                bbox: Float[torch.Tensor, \"X 5\"] = bbox_model(pil).cpu()\n",
        "                wr.writerow([img.file_name] + bbox.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU_U4_tPhEMP"
      },
      "outputs": [],
      "source": [
        "CONFIDENCE: float = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY-U3xLhxvYf"
      },
      "outputs": [],
      "source": [
        "yolo_v5_model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", device=device, _verbose=False)\n",
        "yolo_v5_model.conf = CONFIDENCE\n",
        "yolo_v5_model.eval()\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "586BAcl5SjuT"
      },
      "outputs": [],
      "source": [
        "yolo_v8_model: YOLO = YOLO(\"yolov8x.pt\")\n",
        "yolo_v8_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmDC8BAj1PpT"
      },
      "outputs": [],
      "source": [
        "detr_processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "detr_model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\").to(device)\n",
        "detr_model.eval()\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XC_Y1Laebl--"
      },
      "outputs": [],
      "source": [
        "store_bboxes(\n",
        "    \"YOLOv5\",\n",
        "    lambda img: torch.cat(\n",
        "        [\n",
        "            box[:, :5]\n",
        "            for box in yolo_v5_model(img).xyxy\n",
        "        ]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTz7WZkqiP2M"
      },
      "outputs": [],
      "source": [
        "store_bboxes(\n",
        "    \"YOLOv8\",\n",
        "    lambda img: torch.cat(\n",
        "        [\n",
        "            pred.boxes.data[:, :5]\n",
        "            for pred in yolo_v8_model.predict(img, verbose=False, conf=CONFIDENCE)\n",
        "        ]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Uy8ZRfkei6"
      },
      "outputs": [],
      "source": [
        "def detr_with_conf(image: PIL.Image) -> Float[torch.Tensor, \"X 5\"]:\n",
        "    inputs = detr_processor(images=image, return_tensors=\"pt\")\n",
        "    inputs.to(device)\n",
        "    outputs = detr_model(**inputs)\n",
        "\n",
        "    # convert outputs (bounding boxes and class logits) to COCO API\n",
        "    # let's only keep detections with score > CONFIDENCE\n",
        "    target_sizes = torch.tensor([image.size[::-1]])\n",
        "\n",
        "    return torch.cat(\n",
        "        [\n",
        "            torch.cat((pred[\"boxes\"], pred[\"scores\"].unsqueeze(1)), 1)\n",
        "            for pred in detr_processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=CONFIDENCE)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "store_bboxes(\"DETR\", detr_with_conf)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}