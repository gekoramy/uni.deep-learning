{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVQuq23Q9Hyo"
   },
   "source": [
    "# The big flaw of MLPs\n",
    "\n",
    "Today we will experimentally show what is the **fundamental flaw** of MLPs when it comes to correctly detect visual patterns in the input data, and present it as a motivation for **convolution-based solutions**. In particular, we will compare the performance of our previously implemented MLP on the [MNIST](https://pytorch.org/vision/stable/datasets.html#mnist) dataset with the performance on a **translated version** of the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLLNs9dy9pAM"
   },
   "source": [
    "As usual, we start by importing the modules that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykdTcp1M99JE"
   },
   "source": [
    "## Translation function\n",
    "In this block we are going to define and implement the method which will take care of **transforming** the items in our dataset in such a way to obtain **visually translated** versions of the input digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_translation_transform():\n",
    "    \"\"\"Create a translation transformations.\n",
    "\n",
    "    Creates a transformation that pads the original input so that the\n",
    "    digit is not centered in the image.\n",
    "    \"\"\"\n",
    "\n",
    "    def padding(x):\n",
    "        pad_size = 28\n",
    "        left_padding = torch.randint(low=0, high=pad_size, size=(1,))\n",
    "        top_padding = torch.randint(low=0, high=pad_size, size=(1,))\n",
    "        return F.pad(\n",
    "            x,\n",
    "            (\n",
    "                left_padding,\n",
    "                pad_size - left_padding,\n",
    "                top_padding,\n",
    "                pad_size - top_padding,\n",
    "            ),\n",
    "            \"constant\",\n",
    "            0,\n",
    "        )\n",
    "\n",
    "    translation_transform = list()\n",
    "    translation_transform.append(T.ToTensor())\n",
    "    translation_transform.append(T.Lambda(lambda x: padding(x)))\n",
    "    translation_transform.append(T.Lambda(lambda x: x.repeat(3, 1, 1)))\n",
    "    translation_transform = T.Compose(translation_transform)\n",
    "\n",
    "    return translation_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obE13C39_2g1"
   },
   "source": [
    "## Data loading\n",
    "In this block we want to create a method that returns the required **dataloading utility** over our dataset, in such a way to **choose** whether we want to apply the translation or not by means of a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visualization(batch_size, translate=False):\n",
    "    if not translate:\n",
    "        # image transformation that appends 14 pixels on each side of a digit\n",
    "        transform = list()\n",
    "        transform.append(T.ToTensor())\n",
    "        transform.append(T.Lambda(lambda x: F.pad(x, (14, 14, 14, 14), \"constant\", 0)))\n",
    "        transform = T.Compose(transform)\n",
    "    else:\n",
    "        # applies random translations to images\n",
    "        transform = create_translation_transform()\n",
    "\n",
    "    # load data\n",
    "    full_training_data = torchvision.datasets.MNIST(\n",
    "        \"./data\", train=True, transform=transform, download=True\n",
    "    )\n",
    "\n",
    "    # initialize dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        full_training_data, batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV2v8x0ZBG8y"
   },
   "source": [
    "## Data visualization\n",
    "We want to obtain a visual representation that allows us to **compare** the original digits of the dataset with their translated version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a bunch of training images for visualization over the original and\n",
    "# translated dataset, respectively\n",
    "train_loader = get_data_for_visualization(256, translate=False)\n",
    "train_loader_translated = get_data_for_visualization(256, translate=True)\n",
    "\n",
    "# define iterators over both datasets\n",
    "train_iter, train_iter_translated = iter(train_loader), iter(train_loader_translated)\n",
    "\n",
    "# get labels of original digits\n",
    "data, labels = next(train_iter)\n",
    "\n",
    "# get labels of translated digits\n",
    "data_translated, labels_translated = next(train_iter_translated)\n",
    "\n",
    "# the label of the digit you want to visualize\n",
    "digit_label = 8\n",
    "\n",
    "# get first 9 indices of the chosen digit for non-translated digits\n",
    "get_idx = (labels == digit_label).nonzero().squeeze(-1)[0:9]\n",
    "\n",
    "# get first 9 indices of the chosen digit for translated digits\n",
    "get_idx_translated = (labels_translated == digit_label).nonzero().squeeze(-1)[0:9]\n",
    "\n",
    "# get the data and labels for the chosen digit\n",
    "get_data, get_labels = data[get_idx, :, :, :], labels[get_idx]\n",
    "get_data_translated, get_labels_translated = (\n",
    "    data_translated[get_idx_translated, :, :, :],\n",
    "    labels_translated[get_idx_translated],\n",
    ")\n",
    "\n",
    "\n",
    "### visualize the plots inline, both for original and translated digits ###\n",
    "\n",
    "# original\n",
    "display_grid = torchvision.utils.make_grid(get_data, nrow=3, padding=2, pad_value=1)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(display_grid.numpy().transpose(1, 2, 0))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Centered Digits\")\n",
    "\n",
    "# translated\n",
    "display_grid_translated = torchvision.utils.make_grid(\n",
    "    get_data_translated, nrow=3, padding=2, pad_value=1\n",
    ")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(display_grid_translated.numpy().transpose(1, 2, 0))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Translated Digits\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Az-K8L5oBu3F"
   },
   "source": [
    "## MLP architecture\n",
    "We will use the same architecture that we have discussed and implemented in the previous lab session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFirstNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        # initialize the function\n",
    "        super().__init__()\n",
    "\n",
    "        # first linear layer (input)\n",
    "        self.input_to_hidden = torch.nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # activation function\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "\n",
    "        # second linear layer (output)\n",
    "        self.hidden_to_output = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # initialize bias\n",
    "        self.input_to_hidden.bias.data.fill_(0.0)\n",
    "        self.hidden_to_output.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # puts the output in (batch_size, input_dim) format\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # forward the input through the layers\n",
    "        x = self.input_to_hidden(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.hidden_to_output(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APuCISvfCrP6"
   },
   "source": [
    "## Cost function and optimizer\n",
    "Also for these two components, we stick to those employed in the previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost_function():\n",
    "    cost_function = torch.nn.CrossEntropyLoss()\n",
    "    return cost_function\n",
    "\n",
    "\n",
    "def get_optimizer(net, lr, wd, momentum):\n",
    "    optimizer = torch.optim.SGD(\n",
    "        net.parameters(), lr=lr, weight_decay=wd, momentum=momentum\n",
    "    )\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGxHI0uxFCI0"
   },
   "source": [
    "## Training and test steps\n",
    "We already know the drill!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(net, data_loader, optimizer, cost_function, device=\"cuda\"):\n",
    "    samples = 0.0\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_accuracy = 0.0\n",
    "\n",
    "    # set the network to training mode\n",
    "    net.train()\n",
    "\n",
    "    # iterate over the training set\n",
    "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "        # load data into GPU\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # loss computation\n",
    "        loss = cost_function(outputs, targets)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # parameters update\n",
    "        optimizer.step()\n",
    "\n",
    "        # gradients reset\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # fetch prediction and loss value\n",
    "        samples += inputs.shape[0]\n",
    "        cumulative_loss += loss.item()\n",
    "        _, predicted = outputs.max(\n",
    "            dim=1\n",
    "        )  # max() returns (maximum_value, index_of_maximum_value)\n",
    "\n",
    "        # compute training accuracy\n",
    "        cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return cumulative_loss / samples, cumulative_accuracy / samples * 100\n",
    "\n",
    "\n",
    "def test_step(net, data_loader, cost_function, device=\"cuda\"):\n",
    "    samples = 0.0\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_accuracy = 0.0\n",
    "\n",
    "    # set the network to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    # disable gradient computation (we are only testing, we do not want our model to be modified in this step!)\n",
    "    with torch.no_grad():\n",
    "        # iterate over the test set\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            # load data into GPU\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # loss computation\n",
    "            loss = cost_function(outputs, targets)\n",
    "\n",
    "            # fetch prediction and loss value\n",
    "            samples += inputs.shape[0]\n",
    "            cumulative_loss += (\n",
    "                loss.item()\n",
    "            )  # Note: the .item() is needed to extract scalars from tensors\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            # compute accuracy\n",
    "            cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return cumulative_loss / samples, cumulative_accuracy / samples * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJzgp_pOF-GM"
   },
   "source": [
    "## Data loading\n",
    "Let us now define a compact method to return the dataloaders that we need to perform our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, test_batch_size=128, translate=False):\n",
    "    # define the transformations (same way as before)\n",
    "    if translate:\n",
    "\n",
    "        def padding(x):\n",
    "            pad_size = 28\n",
    "            left_padding = torch.randint(low=0, high=pad_size, size=(1,))\n",
    "            top_padding = torch.randint(low=0, high=pad_size, size=(1,))\n",
    "            return F.pad(\n",
    "                x,\n",
    "                (\n",
    "                    left_padding,\n",
    "                    pad_size - left_padding,\n",
    "                    top_padding,\n",
    "                    pad_size - top_padding,\n",
    "                ),\n",
    "                \"constant\",\n",
    "                0,\n",
    "            )\n",
    "\n",
    "        transform = list()\n",
    "        transform.append(T.ToTensor())\n",
    "        transform.append(T.Lambda(lambda x: padding(x)))\n",
    "        transform = T.Compose(transform)\n",
    "    else:\n",
    "        transform = list()\n",
    "        transform.append(T.ToTensor())\n",
    "        transform.append(T.Lambda(lambda x: F.pad(x, (14, 14, 14, 14), \"constant\", 0)))\n",
    "        transform = T.Compose(transform)\n",
    "\n",
    "    # load data\n",
    "    full_training_data = torchvision.datasets.MNIST(\n",
    "        \"./data\", train=True, transform=transform, download=True\n",
    "    )\n",
    "    test_data = torchvision.datasets.MNIST(\n",
    "        \"./data\", train=False, transform=transform, download=True\n",
    "    )\n",
    "\n",
    "    # split into training and validation sets\n",
    "    num_samples = len(full_training_data)\n",
    "    training_samples = int(num_samples * 0.5 + 1)\n",
    "    validation_samples = num_samples - training_samples\n",
    "\n",
    "    training_data, validation_data = torch.utils.data.random_split(\n",
    "        full_training_data, [training_samples, validation_samples]\n",
    "    )\n",
    "\n",
    "    # initialize dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        validation_data, test_batch_size, shuffle=False\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, test_batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8G6-GK5P0eUM"
   },
   "source": [
    "## Main function\n",
    "Let's now define our wrapper to actually train and evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input arguments:\n",
    "  batch_size: the size of a mini-batch that is used for training\n",
    "  input_dim: flattened size of the input image vector\n",
    "  hidden_dim: number of hidden neurons in the network\n",
    "  output_dim: the number of output neurons\n",
    "  device: GPU where you want to train your network\n",
    "  learning_rate: learning rate for the optimizer\n",
    "  weight_decay: weight decay coefficient for regularization of weights\n",
    "  momentum: momentum for SGD optimizer\n",
    "  epochs: number of epochs for training the network\n",
    "  translate: whether to translate the images that are fed to the network\n",
    "  visualization_name: name of the graph for visualizing in tensorboards\n",
    "                      (always remember to use an unique visualization_name\n",
    "                       for each training, otherwise it will mess up the visualization!)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def main_MLP(\n",
    "    batch_size=64,\n",
    "    input_dim=56 * 56,\n",
    "    hidden_dim=100,\n",
    "    output_dim=10,\n",
    "    device=\"cuda:0\",\n",
    "    learning_rate=0.01,\n",
    "    weight_decay=0.000001,\n",
    "    momentum=0.9,\n",
    "    epochs=50,\n",
    "    translate=False,\n",
    "    visualization_name=\"centered\",\n",
    "):\n",
    "    # creates a logger for the experiment\n",
    "    writer = SummaryWriter(log_dir=f\"runs/{visualization_name}\")\n",
    "\n",
    "    # get dataloaders\n",
    "    train_loader, val_loader, test_loader = get_data(\n",
    "        batch_size=batch_size, translate=translate\n",
    "    )\n",
    "\n",
    "    # correctly set the device\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # instantiate the model and send it to the device\n",
    "    net = MyFirstNetwork(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "    # instantiate optimizer & cost function\n",
    "    optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n",
    "    cost_function = get_cost_function()\n",
    "\n",
    "    # perform a single test step beforehand and print metrics\n",
    "    print(\"Before training:\")\n",
    "    train_loss, train_accuracy = test_step(net, train_loader, cost_function)\n",
    "    val_loss, val_accuracy = test_step(net, val_loader, cost_function)\n",
    "    test_loss, test_accuracy = test_step(net, test_loader, cost_function)\n",
    "\n",
    "    print(\n",
    "        \"\\tTraining loss {:.5f}, Training accuracy {:.2f}\".format(\n",
    "            train_loss, train_accuracy\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"\\tValidation loss {:.5f}, Validation accuracy {:.2f}\".format(\n",
    "            val_loss, val_accuracy\n",
    "        )\n",
    "    )\n",
    "    print(\"\\tTest loss {:.5f}, Test accuracy {:.2f}\".format(test_loss, test_accuracy))\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "    # add values to logger\n",
    "    writer.add_scalar(\"Loss/train_loss\", train_loss, 0)\n",
    "    writer.add_scalar(\"Loss/val_loss\", val_loss, 0)\n",
    "    writer.add_scalar(\"Accuracy/train_accuracy\", train_accuracy, 0)\n",
    "    writer.add_scalar(\"Accuracy/val_accuracy\", val_accuracy, 0)\n",
    "\n",
    "    # iterate over the epochs number\n",
    "    for e in range(epochs):\n",
    "        train_loss, train_accuracy = training_step(\n",
    "            net, train_loader, optimizer, cost_function\n",
    "        )\n",
    "        val_loss, val_accuracy = test_step(net, val_loader, cost_function)\n",
    "        print(\"Epoch: {:d}\".format(e + 1))\n",
    "        print(\n",
    "            \"\\tTraining loss {:.5f}, Training accuracy {:.2f}\".format(\n",
    "                train_loss, train_accuracy\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"\\tValidation loss {:.5f}, Validation accuracy {:.2f}\".format(\n",
    "                val_loss, val_accuracy\n",
    "            )\n",
    "        )\n",
    "        print(\"-----------------------------------------------------\")\n",
    "\n",
    "        # add values to logger\n",
    "        writer.add_scalar(\"Loss/train_loss\", train_loss, e + 1)\n",
    "        writer.add_scalar(\"Loss/val_loss\", val_loss, e + 1)\n",
    "        writer.add_scalar(\"Accuracy/train_accuracy\", train_accuracy, e + 1)\n",
    "        writer.add_scalar(\"Accuracy/val_accuracy\", val_accuracy, e + 1)\n",
    "\n",
    "    # compute and print final metrics\n",
    "    print(\"After training:\")\n",
    "    train_loss, train_accuracy = test_step(net, train_loader, cost_function)\n",
    "    val_loss, val_accuracy = test_step(net, val_loader, cost_function)\n",
    "    test_loss, test_accuracy = test_step(net, test_loader, cost_function)\n",
    "\n",
    "    print(\n",
    "        \"\\t Training loss {:.5f}, Training accuracy {:.2f}\".format(\n",
    "            train_loss, train_accuracy\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"\\t Validation loss {:.5f}, Validation accuracy {:.2f}\".format(\n",
    "            val_loss, val_accuracy\n",
    "        )\n",
    "    )\n",
    "    print(\"\\t Test loss {:.5f}, Test accuracy {:.2f}\".format(test_loss, test_accuracy))\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "    # close the logger\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjZEdZFe1beV"
   },
   "source": [
    "## Run!\n",
    "Let's first run the MLP on the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r runs\n",
    "main_MLP(translate=False, visualization_name=\"centered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxbZNGMY46Ed"
   },
   "source": [
    "Let us now run it on the translated version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_MLP(translate=True, visualization_name=\"translated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHn5waoY8WS5"
   },
   "source": [
    "And see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
