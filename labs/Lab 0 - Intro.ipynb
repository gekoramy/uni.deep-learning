{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xm7rf7fIv3Rg"
   },
   "source": [
    "<img src=https://upload.wikimedia.org/wikipedia/commons/c/c6/PyTorch_logo_black.svg width=\"300\"></br>\n",
    "\n",
    "# Introduction to PyTorch\n",
    "\n",
    "PyTorch is a toolkit implemented in Python, specifically oriented to **developing Deep Learning frameworks**. In particular, this toolkit allows us to build and train deep models in an efficient and intuitive way, which leaves most of the mechanic, yet complex operations to be carried out **automatically**. These involve, in particular:\n",
    "* GPU support\n",
    "* computation of gradients for the back-propagation\n",
    "\n",
    "Today we are going to take a look at the main tools that this scientific library provides:\n",
    "* tensors (concept of computational graph)\n",
    "* modules \n",
    "* loss functions\n",
    "* optimizers\n",
    "* datasets and dataloaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwjUJauex17d"
   },
   "source": [
    "## Tensors and Computational Graphs\n",
    "The goal of computing the gradients of a given function for the optimization process implies the necessity of **tracking** its input and the operations that are applied to them. This tracking results in an object that goes by the name of **Computational Graph**. \n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png\" width=\"500\"></br></br>\n",
    "\n",
    "For each operation that is executed a new node is appended to the graph, allowing us to exploit the **chain rule** in order to compute all the derivatives in a single back-propagation pass. In order to efficiently support this functionality, PyTorch provides a specific class called **Tensor**. A tensor can encode scalar values as well as multidimensional vectors, and supports a wide variety of operations. Let us look at some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOJ6-Ckp0kKm"
   },
   "source": [
    "The tools provided by PyTorch can be made accessible by simply importing `torch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VewavC510wJ4"
   },
   "source": [
    "Let us now create two tensors containing scalar value and define some operations on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tensors. By default tensors do not require gradients, so we enable them\n",
    "a = torch.tensor([2.0], requires_grad=True)\n",
    "b = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "# the result c is also a tensor\n",
    "c = a * b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOtfzxLS09Pe"
   },
   "source": [
    "All the intermediate values of the computation performed in the background by the machine are tracked in order to enable back-propagation. Our computational graph will have a node for `a`, one for `b` and one for the `*` opearation. Let us now compute the gradients of `c = a * b` with respect to one of its inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tensors. By default tensors do not require gradients, so we enable them\n",
    "a = torch.tensor([2.0], requires_grad=True)\n",
    "b = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "# The result c is also a tensor\n",
    "c = a * b\n",
    "\n",
    "print(\"Gradient before computation\")\n",
    "print(a.grad)\n",
    "print(b.grad)\n",
    "c.backward()\n",
    "print(\"Gradient after computation\")\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSiIKj7Q1gP_"
   },
   "source": [
    "Calling the `backward()` method deallocates the computational graph, releasing the memory used to store it, and updates the `grad` attribute of each tensor, summing to it the newly computed gradient. It's easy to see how this automatic differentiation save lots of coding. Take as an example the code that would be needed to manually implement gradient computation in Numpy for a linear layer:\n",
    "\n",
    "\n",
    "```python\n",
    "# define derivative of the activation\n",
    "def derivative_sigmoid(z):\n",
    "  return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "# =========== BACKWARD =========== #\n",
    "\n",
    "# compute gradient from L to z\n",
    "dL_dy = -2 * (t - y)\n",
    "dL_dz = dL_dy * derivative_sigmoid(z)\n",
    "\n",
    "# compute gradient w.r.t. input \n",
    "dL_dx = np.dot(dL_dz, W)\n",
    "\n",
    "# compute gradient w.r.t. parameters\n",
    "dL_dW = np.dot(x, dL_dz)\n",
    "dL_db = dl_dZ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KRUufwa27wv"
   },
   "source": [
    "## Working with different devices\n",
    "Until now, the operations that we performed were executed on **CPU**. PyTorch, however, supports a large range of processors for execution including **GPUs** and **TPUs**. These are called **Devices**. Using the correct device can have a huge impact on **performance**. In order to execute an operation on a specific device, we first need to move all the involved tensors to the memory of such device. The operation will then be automatically executed on that device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the first GPU. In case of multiple GPUs, the index specifies which GPU to use\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# create some tensors in GPU memory\n",
    "a = torch.tensor([2.0], device=device)  # directly create the tensor on GPU\n",
    "b = torch.tensor([3.0]).to(device)  # creates the tensor on CPU and moves it to GPU\n",
    "\n",
    "# the result c is also on GPU\n",
    "c = a * b\n",
    "\n",
    "print(c.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gazgcLlA3rdj"
   },
   "source": [
    "Different operations can also be executed on different devices. PyTorch will automatically keep track of it in the Computational Graph. We now have all the ingredients we need to create and train a deep model. However, using operations at such a low level is unconvenient and prone to errors. We will now look at additional functionalities offered by the library to speed up development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7lwpSH134L7"
   },
   "source": [
    "## Tensor operations\n",
    "PyTorch offers a wide variety of methods to create and manipulate tensors with most of NumPy functions being directly supported. Let us start with an overview of some methods for tensor creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a (2, 3) tensor from python data\n",
    "a = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(a)\n",
    "\n",
    "# creates a (2, 3) tensor with all 0s\n",
    "b = torch.zeros((2, 3), dtype=torch.float32)\n",
    "print(b)\n",
    "\n",
    "# creates a (2, 3) tensor with all 1s\n",
    "c = torch.ones((2, 3), dtype=torch.int32, device=\"cuda:0\")\n",
    "print(c)\n",
    "\n",
    "# creates a (1, 4, 3) tensor with values from a normal distribution\n",
    "# note the extra initial dimension in the output\n",
    "d = torch.randn((1, 4, 3))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHOR27X94RVm"
   },
   "source": [
    "PyTorch supports the basic python operators, which are applied elementwise to the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a (2, 3) tensor from python data\n",
    "a = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(a)\n",
    "\n",
    "# create a (2, 3) tensor with all 1s\n",
    "b = torch.ones((2, 3))\n",
    "print(b)\n",
    "\n",
    "a = a * 2\n",
    "print(\"a * 2\")\n",
    "print(a)\n",
    "\n",
    "print(\"(a * 2) + b\")\n",
    "a = a + b\n",
    "print(a)\n",
    "\n",
    "print(\"((a * 2) + b)^2\")\n",
    "a = a**2\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpC9RtAM4bl2"
   },
   "source": [
    "Other operations, instead, operate on entire dimensions of the tensors and can change their size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a (2, 3) tensor from python data\n",
    "a = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(a)\n",
    "\n",
    "# sum the values in a along the dimension of the rows\n",
    "b = torch.sum(a, dim=0)\n",
    "print(\"torch.sum(a, dim=0)\")\n",
    "print(b)\n",
    "print(b.size())\n",
    "\n",
    "# sum the values in a along the dimension of the columns\n",
    "c = torch.sum(a, dim=1)\n",
    "print(\"torch.sum(a, dim=1)\")\n",
    "print(c)\n",
    "print(c.size())\n",
    "\n",
    "# sum the values in a\n",
    "d = torch.sum(a)\n",
    "print(\"torch.sum(a)\")\n",
    "print(d)\n",
    "print(d.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8RTZ5K-403k"
   },
   "source": [
    "Tensor indexing in PyTorch is quite similar to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a (2, 3) tensor from python data\n",
    "a = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(a)\n",
    "\n",
    "# index a specific scalar\n",
    "print(a[0, 0])\n",
    "\n",
    "# index row 0\n",
    "print(a[0])\n",
    "\n",
    "# index column 0\n",
    "print(a[:, 0])\n",
    "\n",
    "# index columns 0 and 1\n",
    "print(a[:, 0:2])\n",
    "\n",
    "# index the elements greater or equal to 3.0\n",
    "print(a[a >= 3.0])\n",
    "\n",
    "# the returned tensors share the memory with the original tensor\n",
    "a[a >= 3.0] += 10\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qdbcqDr5Flc"
   },
   "source": [
    "PyTorch supports a concept called **Tensor Broadcasting**, which is designed to automatically deal with operations involving tensors of **different sizes**. This often happens in practice, as in the case where an entire tensor is multiplied by a single scalar.\n",
    "\n",
    "Given two tensors, we say that they are \"broadcastable\" if when iterating over their dimensions starting from the last one and proceding towards the initial ones, one of this conditions hold for the size of the dimensions:\n",
    "\n",
    "1. **they match**: no special treatment is needed in this case\n",
    "2. **one of them is 1**: the dimension of size 1 is replicated to make it reach the size of the corresponding dimension in the other tensor\n",
    "3. **one of them does not exist**: the dimension is created with size 1 and the former rule applies\n",
    "\n",
    "Let see some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a (2, 3) tensor\n",
    "a = torch.ones((2, 3))\n",
    "print(a)\n",
    "print(a.size())\n",
    "\n",
    "# create a scalar value with no dimensions\n",
    "b = torch.ones(())\n",
    "print(b)\n",
    "print(b.size())\n",
    "\n",
    "# a (2, 3)\n",
    "# b (2, 3)\n",
    "# We apply rule 3 and b is transformed to\n",
    "# b (2, 3)\n",
    "# Then the sum is performed elementwise\n",
    "c = a + b\n",
    "\n",
    "print(\"Result\")\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a (2, 1, 3) tensor\n",
    "a = torch.ones((2, 1, 3))\n",
    "print(a)\n",
    "print(a.size())\n",
    "\n",
    "# create a (4, 1) tensor\n",
    "b = torch.randn((4, 1))\n",
    "print(b)\n",
    "print(b.size())\n",
    "\n",
    "# a (2, 1, 3)\n",
    "# b ( , 4, 1)\n",
    "# We start from the last dimension and apply rule 2. Tensor b is replicated 3 times on the last dimension\n",
    "# We proceed and apply rule 2. Tensor a is replicated 4 times on the second dimension\n",
    "# We then apply rule 3. An additional initial dimension is created in b and is repeated 2 times\n",
    "# a (2, 4, 3)\n",
    "# b (2, 4, 3)\n",
    "# Then the sum is performed elementwise\n",
    "c = a + b\n",
    "\n",
    "print(\"Result\")\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxjwf53Y553P"
   },
   "source": [
    "The `squeeze()` and `unsqueeze()` methods are often used in conjunction with broadcasting. These methods respectively remove or add a dimension with size 1 in the tensor on which they are called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a (2) tensor\n",
    "a = torch.arange(0, 2)  # [0, 1]\n",
    "print(a)\n",
    "print(a.size())\n",
    "\n",
    "# create a (3) tensor\n",
    "b = torch.arange(0, 3)  # [0, 1, 2]\n",
    "print(b)\n",
    "print(b.size())\n",
    "\n",
    "# Say we want to multiply each element in a with each element in b, getting a (2, 3) tensor\n",
    "# Leveraging broadcast, we can add a trailing 1 dimension to a and multiply\n",
    "\n",
    "print(\"\\nUnsqueezed a\")\n",
    "a = a.unsqueeze(dim=-1)\n",
    "print(a)\n",
    "print(a.size())\n",
    "\n",
    "# a is (2, )\n",
    "# b is ( , 3)\n",
    "# c is (2, 3)\n",
    "c = a * b\n",
    "print(\"\\nResult\")\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ct7XJEy54Hp"
   },
   "source": [
    "PyTorch adopts some conventions on the shape of the tensors expected by its modules. 1D data is typically represented in the `(batch_size, features_count)` format. 2D data instead is represented in the `(batch_size, channels, height, width)` format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24uz0xAc6aFt"
   },
   "source": [
    "## Modules\n",
    "Let use what we learned so far to implement a simple linear layer:\n",
    "`y = Wx + b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "in_features = 8\n",
    "out_features = 16\n",
    "\n",
    "\n",
    "def apply_linear_layer(x, W, b):\n",
    "    \"\"\"Apply a linear layer on an input.\n",
    "\n",
    "    Args:\n",
    "      x (batch_size, in_features)\n",
    "      W (out_features, in_features)\n",
    "      b (out_features)\n",
    "    \"\"\"\n",
    "\n",
    "    # (batch_size, in_features, 1)\n",
    "    x = x.unsqueeze(-1)\n",
    "    # (1, out_features, in_features)\n",
    "    W = W.unsqueeze(0)\n",
    "\n",
    "    # (batch_size, out_features, 1)\n",
    "    product = torch.matmul(W, x).squeeze(-1)\n",
    "\n",
    "    # (batch_size, out_features)\n",
    "    result = product + b\n",
    "    return result\n",
    "\n",
    "\n",
    "x = torch.randn((batch_size, in_features))\n",
    "\n",
    "# Weights of the linear layer\n",
    "W = torch.randn((out_features, in_features), requires_grad=True)\n",
    "b = torch.zeros((out_features), requires_grad=True)\n",
    "\n",
    "output = apply_linear_layer(x, W, b)\n",
    "print(\"Result\")\n",
    "print(output)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aplxYH736pq_"
   },
   "source": [
    "While the layer is functional, instantiating multiple such layers quickly becomes **unmanageable**. The main problem lies in the fact that the weights of the layer **are not tied** with the computational logic: creating a **class** for the layer would solve this problem. PyTorch provides a base class (`torch.nn.Module`) for such purpose, which provides a variety of functionalities.\n",
    "\n",
    "Let's implement our linear layer in PyTorch style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \"\"\"Linear layer.\n",
    "\n",
    "        Args:\n",
    "          in_features: number of input features\n",
    "          out_features: number of output features\n",
    "        \"\"\"\n",
    "        super(Linear, self).__init__()\n",
    "\n",
    "        # Creates tensors for the weights\n",
    "        W = torch.randn((out_features, in_features))\n",
    "        b = torch.zeros((out_features))\n",
    "\n",
    "        # Uses the Parameter class (subclass of Tensor) to create parameters for the module\n",
    "        # When assigned to a member of self, Parameter tensors are automatically registered\n",
    "        # Require gradient by default\n",
    "        # Other Module objects are also automatically registered if assigned to self\n",
    "        self.W = nn.Parameter(W)\n",
    "        self.b = nn.Parameter(b)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Method executed when the object is called.\n",
    "\n",
    "        Args:\n",
    "          x (batch_size, in_features)\n",
    "\n",
    "        Return:\n",
    "          tensors (batch_size, out_features)\n",
    "        \"\"\"\n",
    "\n",
    "        # (batch_size, in_features, 1)\n",
    "        x = x.unsqueeze(-1)\n",
    "        # Note that Parameters\n",
    "        # (1, out_features, in_features)\n",
    "        W = self.W.unsqueeze(0)\n",
    "\n",
    "        # (batch_size, out_features, 1)\n",
    "        product = torch.matmul(W, x).squeeze(-1)\n",
    "\n",
    "        # (batch_size, out_features)\n",
    "        result = product + self.b\n",
    "        return result\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "in_features = 8\n",
    "out_features = 16\n",
    "\n",
    "x = torch.randn((batch_size, in_features))\n",
    "\n",
    "# Creates an instance of our linear layer\n",
    "linear_layer = Linear(in_features, out_features)\n",
    "# Computes the results. the forward method is internally called\n",
    "output = linear_layer(x)\n",
    "\n",
    "print(\"Result\")\n",
    "print(output)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brgzsx9t7K7R"
   },
   "source": [
    "Note how now both the parameters, their initialization and the processing logic are contained in the class. Multiple instances can be handled more conveniently. The Module class provides a range of additional functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain all the parameters in the model. Useful for model optimization\n",
    "parameters = linear_layer.parameters()\n",
    "for parameter in parameters:\n",
    "    print(parameter)\n",
    "\n",
    "# move all the tensors associated to the model to the specified device\n",
    "# recursively applies to other Module objects contained in the instance\n",
    "linear_layer.to(\"cuda:0\")\n",
    "\n",
    "# obtain a representation of the model and saves it\n",
    "print(\"Saving model\")\n",
    "saved_model = linear_layer.state_dict()\n",
    "torch.save(saved_model, \"save.pth\")\n",
    "\n",
    "# load the saved model\n",
    "print(\"Loading model\")\n",
    "loaded_state_dict = torch.load(\"save.pth\")\n",
    "linear_layer.load_state_dict(loaded_state_dict)\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lxffBzC7atH"
   },
   "source": [
    "PyTorch provides a wide range of `Module` implementations representing the most common computational blocks. These include\n",
    "\n",
    "*   Linear layers\n",
    "*   1D, 2D and 3D Convolutions\n",
    "*   Transposed Convolutions\n",
    "*   Batch Normalization layers\n",
    "*   RNN, LSTM, GRU cells\n",
    "*   ...\n",
    "\n",
    "Moreover, many common networks are implemented as `Module`s\n",
    "\n",
    "*   Alexnet\n",
    "*   VGG\n",
    "*   ResNet\n",
    "*   DenseNet\n",
    "*   ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUG64uMf7kFP"
   },
   "source": [
    "## Loss functions\n",
    "\n",
    "PyTorch provides a wide range of already implemented loss functions as part of `torch.nn`\n",
    "\n",
    "*   L1\n",
    "*   MSE\n",
    "*   Cross Entropy\n",
    "*   Binary Cross Entropy\n",
    "\n",
    "Let see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# create some tensors for the loss\n",
    "x = torch.zeros((2, 4))\n",
    "y = torch.ones((2, 4)) * 2\n",
    "\n",
    "# instantiate the loss\n",
    "l1_loss = nn.L1Loss()\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "# compute the loss functions\n",
    "loss = l1_loss(x, y)\n",
    "print(loss)\n",
    "\n",
    "loss = mse_loss(x, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPF6ODoM8agv"
   },
   "source": [
    "## Optimizers\n",
    "\n",
    "PyTorch implements a wide range of optimizers as part of the `torch.optim` package. When an optimizer is created, a sequence of tensors to optimize is required. The optimizer then uses the `grad` attribute of each to update their value.\n",
    "\n",
    "A typical optimization cycle is made of the following steps:\n",
    "\n",
    "1.   perform the computations that build the Computational Graph\n",
    "2.   compute the loss term\n",
    "3.   use `backward()` to compute gradients for each tensor in the Computational Graph\n",
    "4.   perform an optimization step using the optimizer\n",
    "5.   zero the gradient in all tensors for the next optimization cycle using `zero_grad()`\n",
    "\n",
    "Let see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "in_features = 8\n",
    "out_features = 4\n",
    "batch_size = 4\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# create tensors for the loss\n",
    "x = torch.zeros((batch_size, in_features))\n",
    "y = torch.ones((batch_size, out_features))\n",
    "\n",
    "# create the model to optimize\n",
    "model = nn.Linear(in_features, out_features)\n",
    "\n",
    "# the tensors whose value will be optimized\n",
    "parameters = model.parameters()\n",
    "# instantiate the optimizer\n",
    "optimizer = torch.optim.SGD(parameters, learning_rate)\n",
    "\n",
    "# instantiate the loss\n",
    "l1_loss = nn.L1Loss()\n",
    "\n",
    "# =========== perform an optimization step =========== #\n",
    "\n",
    "# 1. perform computations\n",
    "y_pred = model(x)\n",
    "\n",
    "# 2. compute the loss term\n",
    "loss = l1_loss(y_pred, y)\n",
    "\n",
    "# 3. compute the gradients on the loss term\n",
    "#    all tensors involved in the computation now have a\n",
    "#    .grad value\n",
    "loss.backward()\n",
    "\n",
    "# 4. perform the optimization step with the gradient values in .grad\n",
    "optimizer.step()\n",
    "\n",
    "# 5. set all .grad attributes to 0 for the next optimization cycle\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# ==================================================== #\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MI26r5hx9K7K"
   },
   "source": [
    "## Datasets and Dataloaders\n",
    "\n",
    "While we could manually load training data into input tensors, doing so would be a major performance bottleneck in the training of a deep model. For this reason, PyTorch provides a range of utilities in the `torch.utils.data` package that help us efficiently dealing with data. The most relevant ones are the `Dataset` and `DataLoader` classes.\n",
    "\n",
    "* the `Dataset` class represents our training data and contains the logic to load a single element. We typically subclass it when creating a new dataset.\n",
    "\n",
    "* the `DataLoader` class is an utility class that efficiently loads a batch of data from a dataset. Multiprocessing is used to speed up data processing and to overlap the processing of the next batch with the current model computations.\n",
    "\n",
    "Subclassing the Dataset class requires overriding the `__len__` and the `__getitem__` methods to return respectively the number of elements in the dataset and the item at a speficied position. Any object type can be returned by the `__getitem__` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    \"\"\"A simple dataset representing the numbers from 0 to size-1\"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        super(SimpleDataset, self).__init__()\n",
    "\n",
    "        self.size = size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get an item given its id.\n",
    "\n",
    "        Args:\n",
    "          idx: the integral index of the element to retrieve\n",
    "\n",
    "        Returns:\n",
    "          element at index idx\n",
    "        \"\"\"\n",
    "        return torch.tensor([idx], dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "          number of elements that compose the dataset\n",
    "        \"\"\"\n",
    "        return self.size\n",
    "\n",
    "\n",
    "size = 10\n",
    "\n",
    "# instantiate the dataset\n",
    "dataset = SimpleDataset(size)\n",
    "\n",
    "# fetch the length of the dataset (__len__ method)\n",
    "length = len(dataset)\n",
    "print(f\"Dataset length: {length}\")\n",
    "\n",
    "# get each element of the dataset through indexing\n",
    "# (__getitem__ method)\n",
    "for idx in range(len(dataset)):\n",
    "    print(f\"- {idx}: {dataset[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DeUQXJK9oab"
   },
   "source": [
    "A range of methods are provided to conveniently work with datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 6\n",
    "val_size = 2\n",
    "test_size = 2\n",
    "\n",
    "# split the dataset into training, validation and test sets\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "# print all the splits\n",
    "for current_dataset in [train_dataset, val_dataset, test_dataset]:\n",
    "    current_length = len(current_dataset)\n",
    "    print(f\"Current length: {current_length}\")\n",
    "    for idx in range(current_length):\n",
    "        print(f\"- {idx}: {current_dataset[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRi07gnK9zcg"
   },
   "source": [
    "Once a `Dataset` instance is available, a `DataLoader` object can be used to efficiently gather batches of data from the dataset. We just need to specify the size of the batch we would like to retrieve, the number of parallel workers to use for data processing and whether or not we would like batch elements to be sampled randomly from the dataset.\n",
    "\n",
    "The DataLoader object is iterable and yields a batch of data at each iteration. Internally, when a batch is requested, the dataloader uses the `Dataset` `__getitem__` method to retrieve each item in the batch. If the object type returned by this function is known to PyTorch (eg. it is a Tensor), then they are automatically combined into a single object representing the batch. For example, if the returned type is Tensor, PyTorch fuses all Tensors composing the batch into a single Tensor with an additional initial dimension of size equal to the batch size. If the dataset returns custom data types instead a `collate_fn` function can be manually specified that takes as input a list of objects returned by dataset and returns a single object representing the entire batch.\n",
    "\n",
    "Due to `DataLoader parallelism, PyTorch recommends that objects returned by datasets be placed in CPU memory due to the subtleties in handling objects placed in GPU memory from multiple processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Creates a dataloader for our dataset instance.\n",
    "# Does not randomize the order of elements and returns the last batch even if\n",
    "# it is not of size batch_size\n",
    "dataloader = DataLoader(\n",
    "    dataset, num_workers=2, batch_size=4, shuffle=False, drop_last=False\n",
    ")\n",
    "\n",
    "print(\"Unshuffled DataLoader\")\n",
    "for idx, batch in enumerate(dataloader):\n",
    "    print(f\"Batch {idx}:\")\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLvW5P2q-J4T"
   },
   "source": [
    "## Transformations\n",
    "\n",
    "The `Dataset` class gives us the freedom to insert data augmentation strategies directly inside the `__getitem__` method implementation. Doing so, however, is inconvenient since for the same dataset we may want to apply different augmentation, for example during training and during evaluation.\n",
    "\n",
    "For this reason, a typical pattern in PyTorch is providing to the Dataset constructor a `transform` function. The Dataset class, will apply the desired transformations **before** returning the `__getitem__` value, thus actually returning `transform(__getitem__(idx))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TransformableDataset(Dataset):\n",
    "    \"\"\"A simple dataset class representing the numbers from 0 to size - 1\"\"\"\n",
    "\n",
    "    def __init__(self, size, transform=None):\n",
    "        super(TransformableDataset, self).__init__()\n",
    "\n",
    "        self.transform = transform\n",
    "        self.size = size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get an item given its id.\n",
    "\n",
    "        Args:\n",
    "          idx: the integral index of the element to retrieve\n",
    "\n",
    "        Returns:\n",
    "          element at index idx\n",
    "        \"\"\"\n",
    "        result = torch.tensor([idx], dtype=torch.float32)\n",
    "\n",
    "        # if a transformation is available, we apply it\n",
    "        if self.transform is not None:\n",
    "            result = self.transform(result)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "          number of elements that compose the dataset\n",
    "        \"\"\"\n",
    "        return self.size\n",
    "\n",
    "\n",
    "# a simple transformation\n",
    "def square(input):\n",
    "    return input**2\n",
    "\n",
    "\n",
    "size = 10\n",
    "\n",
    "# instantiates the dataset\n",
    "dataset = TransformableDataset(size, transform=square)\n",
    "\n",
    "# Gets the length of the dataset (__len__ method)\n",
    "length = len(dataset)\n",
    "print(f\"Dataset length: {length}\")\n",
    "\n",
    "# Gets each element of the dataset through indexing\n",
    "# (__getitem__ method)\n",
    "for idx in range(len(dataset)):\n",
    "    print(f\"- {idx}: {dataset[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezJqpWrb-t9M"
   },
   "source": [
    "Many transformations are available in PyTorch. In particular, the `torchvision.transforms` package contains a range of transformations designed for images, together with utilities to compose a complex chain of transformations into a single pipeline.\n",
    "\n",
    "When designing a transformation, it is important to consider that PyTorch datasets typically return images represented by the PIL Image class, which is the format expected by many of the transformations in the `torchvision.transforms` package. The `ToTensor` transformation can be used to convert PIL Images to Tensors.\n",
    "\n",
    "Let see an example where we will use a dataset of images provided by PyTorch returning PIL Images, and apply some typical transformations to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Obtains the CIFAR10 dataset, downloading it if necessary\n",
    "# Each returned element is a tuple (PIL Image, int) with the int representing the label of the image\n",
    "# transform is applied only to the first element in the tuple\n",
    "# target_transform can be specified for the second element\n",
    "dataset = torchvision.datasets.CIFAR10(root=\"cifar\", transform=None, download=True)\n",
    "\n",
    "# Plots the first image\n",
    "sample_image, sample_label = dataset[0]\n",
    "plt.imshow(np.asarray(sample_image))\n",
    "print(f\"Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# build a transformation that will apply a random affine transformation\n",
    "affine_transformation = transforms.RandomAffine(degrees=20, translate=(0.1, 0.1))\n",
    "\n",
    "# transform and plot the first image\n",
    "transformed_image = affine_transformation(sample_image)\n",
    "plt.imshow(np.asarray(transformed_image))\n",
    "\n",
    "# build a chain of transformations\n",
    "transformations_sequence = [\n",
    "    affine_transformation,\n",
    "    # random changes in pixel colors\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    # the former transformations accept and return PIL Image objects, now convert to Tensor\n",
    "    transforms.ToTensor(),\n",
    "    # apply normalization\n",
    "    transforms.Normalize(mean=[0.4913, 0.4821, 0.4465], std=[0.2470, 0.2434, 0.2615]),\n",
    "]\n",
    "\n",
    "composed_transformation = transforms.Compose(transformations_sequence)\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"cifar\", transform=composed_transformation, download=True\n",
    ")\n",
    "# show the first image\n",
    "transformed_image, sample_label = dataset[0]\n",
    "print(\"Sample image\")\n",
    "print(transformed_image)\n",
    "print(f\"Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Szh0JdG5_Yms"
   },
   "source": [
    "## Logging\n",
    "\n",
    "Understanding the training behavior of deep models is often challenging. A wide variety of metrics, however, can give us clues on why a certain behavior is shown. Moreover, when working on a deep learning project, multiple configurations and architecture variations are typically tested, generating a large quantity of data. Being able to explore these data and to compare them among different configurations is thus of primary importance.\n",
    "\n",
    "Multiple tools are available to achieve these goal. In this unit we will cover two main logging utilities: Tensorboard and WandB. The idea behind these tools is simple: when training or evaluating a model, we log some metrics at each step, and the tool provides us with a web interface where plots showing the dynamics of our model are automatically populated.\n",
    "\n",
    "Let start with a Tensorboard example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# ====== write fake data representing a first experiment ====== #\n",
    "\n",
    "\n",
    "# creates a logger for the experiment\n",
    "writer = SummaryWriter(log_dir=\"runs/exp1\")\n",
    "\n",
    "# simulate 100 training steps\n",
    "for training_step in range(100):\n",
    "    # log training metrics\n",
    "    writer.add_scalar(\"train/quantity_a\", training_step * 0.5, training_step)\n",
    "    writer.add_scalar(\"train/quantity_b\", training_step**1.5, training_step)\n",
    "    writer.add_scalar(\"train/quantity_c\", 1 / (1 + training_step), training_step)\n",
    "\n",
    "# close the logger\n",
    "writer.close()\n",
    "\n",
    "# ============================================================== #\n",
    "\n",
    "# ====== write fake data representing a second experiment ====== #\n",
    "\n",
    "### write fake data representing a second experiment\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"runs/exp2\")\n",
    "\n",
    "for training_step in range(100):\n",
    "    writer.add_scalar(\"train/quantity_a\", training_step * 0.4, training_step)\n",
    "    writer.add_scalar(\"train/quantity_b\", training_step**1.4, training_step)\n",
    "    writer.add_scalar(\"train/quantity_c\", 1 / (1 + 2 * training_step), training_step)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# ============================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if getting an error, enable third party cookies!\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jU8ZlizCAkTc"
   },
   "source": [
    "Let's now try out WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "wandb.init(project=\"lab_01_intro\", name=\"exp1\")\n",
    "\n",
    "# simulate 100 training steps\n",
    "for training_step in range(100):\n",
    "    # log training metrics\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"train/quantity_a\": training_step * 0.5,\n",
    "            \"train/quantity_b\": training_step**1.5,\n",
    "            \"train/quantity_c\": 1 / (1 + training_step),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# ====== write fake data representing a second experiment ====== #\n",
    "\n",
    "wandb.init(project=\"lab_01_intro\", name=\"exp2\")\n",
    "\n",
    "for training_step in range(100):\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"train/quantity_a\": training_step * 0.4,\n",
    "            \"train/quantity_b\": training_step**1.3,\n",
    "            \"train/quantity_c\": 1 / (1 + 2 * training_step),\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
